{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "設定一些東西齁\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "from transformers import BertTokenizer\n",
    "import transformers\n",
    "import ckip_transformers\n",
    "from ckiptagger import WS, POS, NER\n",
    "from ckip_transformers.nlp import CkipPosTagger\n",
    "from ckip_transformers.nlp import CkipWordSegmenter\n",
    "from ckip_transformers.nlp import CkipNerChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer_config.json: 100%|██████████| 29.0/29.0 [00:00<00:00, 3.00kB/s]\n",
      "Downloading vocab.txt: 100%|██████████| 110k/110k [00:00<00:00, 280kB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 269k/269k [00:00<00:00, 523kB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer=BertTokenizer.from_pretrained(\"bert-base-chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unk_token': '[UNK]',\n",
       " 'sep_token': '[SEP]',\n",
       " 'pad_token': '[PAD]',\n",
       " 'cls_token': '[CLS]',\n",
       " 'mask_token': '[MASK]',\n",
       " 'additional_special_tokens': ['[unused1]']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens =\"[unused1]\"\n",
    "#tokens =['[unused1]']\n",
    "tokenizer.add_tokens(tokens, special_tokens=True)\n",
    "tokenizer.save_pretrained('path/to/save/tokenizer')\n",
    "tokenizer.special_tokens_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|██████████| 2.86k/2.86k [00:00<00:00, 327kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 407M/407M [00:59<00:00, 6.84MB/s] \n",
      "Downloading tokenizer_config.json: 100%|██████████| 301/301 [00:00<00:00, 38.2kB/s]\n",
      "Downloading vocab.txt: 100%|██████████| 110k/110k [00:00<00:00, 450kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 44.2kB/s]\n",
      "Downloading config.json: 100%|██████████| 804/804 [00:00<00:00, 104kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 407M/407M [01:06<00:00, 6.08MB/s] \n",
      "Downloading tokenizer_config.json: 100%|██████████| 301/301 [00:00<00:00, 28.6kB/s]\n",
      "Downloading vocab.txt: 100%|██████████| 110k/110k [00:00<00:00, 919kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 36.0kB/s]\n",
      "Downloading config.json: 100%|██████████| 3.71k/3.71k [00:00<00:00, 428kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 407M/407M [00:57<00:00, 7.05MB/s] \n",
      "Downloading tokenizer_config.json: 100%|██████████| 301/301 [00:00<00:00, 32.1kB/s]\n",
      "Downloading vocab.txt: 100%|██████████| 110k/110k [00:00<00:00, 342kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 30.5kB/s]\n"
     ]
    }
   ],
   "source": [
    "#ws = WS(\"./data\")\n",
    "#pos = POS(\"./data\")\n",
    "#ner = NER(\"./data\")\n",
    "CKIP_POS=CkipPosTagger(model=\"bert-base\",device=-1)\n",
    "CKIP_WS=CkipWordSegmenter(model=\"bert-base\",device=-1)\n",
    "CKIP_NER=CkipNerChunker(model=\"bert-base\",device=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本前處理\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正式文本\n",
    "---\n",
    "<span style=\"color:red\">這邊只有先做1000筆 之後再多做然後寫入txt</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Obama大勝美國首位黑人總統',\n",
       " '駐美特派員曹郁芬華府五日報導',\n",
       " '歐巴瑪Obama大勝美國首位黑人總統',\n",
       " '壓倒性勝利創造新歷史',\n",
       " '民主黨總統候選人歐巴瑪四日以壓倒性勝利，']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"語料/原始華語.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    data=f.readlines()\n",
    "full_formal_text=[]\n",
    "for i in data:\n",
    "    full_formal_text.append(i[:-1])\n",
    "full_formal_text[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64110"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#64110\n",
    "#<25 61308\n",
    "len(full_formal_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "formal_text=full_formal_text[0:60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization:   0%|          | 0/59998 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 59998/59998 [00:05<00:00, 10467.93it/s]\n",
      "Inference:   2%|▏         | 4/235 [03:32<3:24:03, 53.00s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6a987ff5b7c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#pos_results = pos(ws_results)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#ner_results = ner(ws_results, pos_results)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mformal_ws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCKIP_WS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformal_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mformal_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCKIP_POS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformal_ws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mformal_ner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCKIP_NER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformal_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/ckip_transformers/nlp/driver.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_text, use_delim, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mindex_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         ) = super().__call__(input_text, use_delim=use_delim, **kwargs)\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# Post-process results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/ckip_transformers/nlp/util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_text, use_delim, delim_set, batch_size, max_length, show_progress, pin_memory)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mbatch_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mbatch_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Remove [CLS]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1756\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1758\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1759\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1020\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m         )\n\u001b[0;32m-> 1022\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1023\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    610\u001b[0m                 )\n\u001b[1;32m    611\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    613\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         )\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#ws_results = ws(data[2])\n",
    "#pos_results = pos(ws_results)\n",
    "#ner_results = ner(ws_results, pos_results)\n",
    "formal_ws=CKIP_WS(formal_text)\n",
    "formal_pos=CKIP_POS(formal_ws)\n",
    "formal_ner=CKIP_NER(formal_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Obama', '大勝', '美國', '首位', '黑人', '總統']"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formal_ws[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NerToken(word='Obama', ner='PERSON', idx=(0, 5)),\n",
       " NerToken(word='美國', ner='GPE', idx=(7, 9)),\n",
       " NerToken(word='首', ner='ORDINAL', idx=(9, 10))]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formal_ner[0]\n",
    "#replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_ner(sent,ner_filter):\n",
    "    filter_ner_sent=[]\n",
    "    for j,word in enumerate(sent):\n",
    "        if word.ner in ner_filter:\n",
    "            filter_ner_sent.append(word.idx)\n",
    "            \n",
    "    return filter_ner_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 5)]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_filter=[\"PERSON\"]\n",
    "formal_ner_person=[filter_by_ner(sent,ner_filter) for sent in formal_ner]\n",
    "formal_ner_person[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in formal_ner_person:\n",
    "    if i!=[]:\n",
    "        text_slice=formal_text[count]\n",
    "        starts, ends = zip(*i)\n",
    "        start_slices = [int(start) for start in starts]\n",
    "        end_slices = [int(end) for end in ends]\n",
    "        person=(f\"{i[0][0]}:{i[0][1]}\")\n",
    "        for x in range(len(start_slices)):\n",
    "            #print(formal_text[count][start_slices[x]:end_slices[x]])\n",
    "            formal_text[count]=formal_text[count].replace(formal_text[count][start_slices[x]:end_slices[x]],\"[unused1]\")\n",
    "            #print(formal_text[count])\n",
    "    count+=1\n",
    "formal_noname=formal_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Obama大勝美國首位黑人總統'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formal_noname[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "與 蘇治芬 的 辯護律師 李進勇 、 顧立雄 、 蔡易餘 為了是否 延押 激烈攻防，\n",
      "於 上個月 二十五日 發表的 「 二OO八年 聯合作戰 環境 評價 報告 」 中 ，\n"
     ]
    }
   ],
   "source": [
    "#數字\n",
    "formal_tensor=[]\n",
    "#[PAD]\n",
    "formal_token=[]\n",
    "\n",
    "for text in formal_noname:\n",
    "    tensor=tokenizer.encode(text)\n",
    "    if len(tensor)<=30:\n",
    "        tensor_fill=tensor+ [0] * (25 - len(tensor))\n",
    "        formal_tensor.append(tensor_fill)\n",
    "        formal_token.append(tokenizer.decode(tensor_fill))\n",
    "    else:\n",
    "        print(text)\n",
    "        formal_noname.remove(text)\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59996"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(formal_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_formal_tensor=formal_tensor[:]\n",
    "for i in new_formal_tensor:\n",
    "    if len(i)>25:\n",
    "        formal_tensor.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59962"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(formal_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama大勝美國首位黑人總統\n",
      "\n",
      "\n",
      "[101, 100, 1920, 1245, 5401, 1751, 7674, 855, 7946, 782, 5244, 5186, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "\n",
      "[CLS] [UNK] 大 勝 美 國 首 位 黑 人 總 統 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(formal_text[0])\n",
    "print(\"\\n\")\n",
    "print(formal_tensor[0])\n",
    "print(\"\\n\")\n",
    "print(formal_token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"formal.txt\", \"w\",encoding='UTF-8') as file:\n",
    "    for item in formal_text:\n",
    "        file.write(str(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"formal_tensor.txt\", \"w\",encoding='UTF-8') as file:\n",
    "    for item in formal_tensor:\n",
    "        file.write(str(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"formal_token.txt\", \"w\",encoding='UTF-8') as file:\n",
    "    for item in formal_token:\n",
    "        file.write(str(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "非正式文本\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'質感劇本成員都差很多好嗎不要拿腎結石來污辱這群人'"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "informal_text=[] \n",
    "with open(\"Gossiping-QA-Dataset-2_0.csv\", mode=\"r\", encoding=\"utf-8-sig\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "    for row in reader:\n",
    "        r=row[1].replace(\" \",\"\")\n",
    "        r=r.replace(\",\",\"\")\n",
    "        r=r.replace(\".\",\"\")\n",
    "        r=r.replace(\"。\",\"\")\n",
    "        informal_text.append(r)\n",
    "       \n",
    "informal_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774114"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(informal_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'質感劇本成員都差很多好嗎不要拿腎結石來污辱這群人'"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informal_text=informal_text[0:80000]\n",
    "informal_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 60000/60000 [00:04<00:00, 13862.28it/s]\n",
      "Inference: 100%|██████████| 235/235 [25:53<00:00,  6.61s/it]\n",
      "Tokenization: 100%|██████████| 60000/60000 [00:01<00:00, 59282.36it/s]\n",
      "Inference: 100%|██████████| 292/292 [31:54<00:00,  6.56s/it]\n",
      "Tokenization: 100%|██████████| 60000/60000 [00:01<00:00, 41547.01it/s]\n",
      "Inference: 100%|██████████| 235/235 [25:22<00:00,  6.48s/it]\n"
     ]
    }
   ],
   "source": [
    "informal_ws=CKIP_WS(informal_text)\n",
    "informal_pos=CKIP_POS(informal_ws)\n",
    "informal_ner=CKIP_NER(informal_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_filter=[\"PERSON\"]\n",
    "informal_ner_person=[filter_by_ner(sent,ner_filter) for sent in informal_ner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in informal_ner_person:\n",
    "    if i!=[]:\n",
    "        text_slice=informal_text[count]\n",
    "        starts, ends = zip(*i)\n",
    "        start_slices = [int(start) for start in starts]\n",
    "        end_slices = [int(end) for end in ends]\n",
    "        person=(f\"{i[0][0]}:{i[0][1]}\")\n",
    "        for x in range(len(start_slices)):\n",
    "            #print(formal_text[count][start_slices[x]:end_slices[x]])\n",
    "            informal_text[count]=informal_text[count].replace(informal_text[count][start_slices[x]:end_slices[x]],\"[unused1]\")\n",
    "            #print(formal_text[count])\n",
    "    count+=1\n",
    "informal_noname=informal_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "#數字\n",
    "informal_tensor=[]\n",
    "#[PAD]\n",
    "informal_token=[]\n",
    "\n",
    "for text in informal_noname:\n",
    "    tensor=tokenizer.encode(text)\n",
    "    if len(tensor)<=40:\n",
    "        tensor_fill=tensor+ [0] * (25 - len(tensor))\n",
    "        informal_tensor.append(tensor_fill)\n",
    "        informal_token.append(tokenizer.decode(tensor_fill))\n",
    "    else:informal_noname.remove(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 6549, 2697, 1206, 3315, 2768, 1519, 6963, 2345, 2523, 1914, 1962, 1621, 679, 6206, 2897, 5575, 5178, 4767, 889, 3738, 6802, 6857, 5408, 782, 102]\n",
      "\n",
      "\n",
      "[CLS] 質 感 劇 本 成 員 都 差 很 多 好 嗎 不 要 拿 腎 結 石 來 污 辱 這 群 人 [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(informal_tensor[0])\n",
    "print(\"\\n\")\n",
    "print(informal_token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_informal_tensor=informal_tensor[:]\n",
    "for i in new_informal_tensor:\n",
    "    if len(i)>25:\n",
    "        informal_tensor.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59955"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(informal_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"informal.txt\", \"w\",encoding='UTF-8') as file:\n",
    "    for item in informal_text:\n",
    "        file.write(str(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">生成器</span>\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BertLMHeadModel 訓練 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FORMAL\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|██████████| 624/624 [00:00<00:00, 70.5kB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 412M/412M [01:00<00:00, 6.85MB/s] \n",
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=21128, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM,BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained('ckiplab/bert-tiny-chinese')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-chinese') \n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"formal.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    data=f.readlines()\n",
    "formal_text=[]\n",
    "for i in data:\n",
    "    formal_text.append(i[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=[]\n",
    "for i in formal_text:\n",
    "    x=i.replace(\" \",'')\n",
    "    f.append(x)\n",
    "    \n",
    "formal_text=f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59963"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(formal_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "formal_longer=[]\n",
    "for i in range(0,len(formal_text)-5,5):\n",
    "    text=formal_text[i]+formal_text[i+1]+formal_text[i+2]+formal_text[i+3]+formal_text[i+4]\n",
    "    formal_longer.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11992"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(formal_longer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=tokenizer(formal_longer,return_tensors=\"pt\", padding=True, truncation=True)[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,   138,   163, 11316,  8303,  8148,   140,  1920,  1245,  5401,\n",
       "         1751,  7674,   855,  7946,   782,  5244,  5186,  7688,  5401,  4294,\n",
       "         3836,  1519,   138,   163, 11316,  8303,  8148,   140,  5836,  2424,\n",
       "          758,  3189,  1841,  2206,   138,   163,  8171,   138,   163, 11316,\n",
       "         8303,  8148,   140,   140,   100,  1920,  1245,  5401,  1751,  7674,\n",
       "          855,  7946,   782,  5244,  5186,  1886,   948,  2595,  1245,  1164,\n",
       "         1201,  6863,  3173,  3644,  1380,  3696,   712,  7955,  5244,  5186,\n",
       "          952,  6908,   782,   138,   163, 11316,  8303,  8148,   140,  1724,\n",
       "         3189,   809,  1886,   948,  2595,  1245,  1164,  8024,   102,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.3970, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2658, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3929, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    dataset = TensorDataset(input_ids)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    for batch in dataloader:\n",
    "        outputs = model(input_ids=batch[0])\n",
    "        loss = criterion(outputs.logits.view(-1, model.config.vocab_size), batch[0].view(-1))\n",
    "        print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_pretrained(\"formal_model\")\n",
    "#model.save_pretrained(\"formal_model_large\")\n",
    "#model.save_pretrained(\"formal_model_large_nospace\")\n",
    "#model.save_pretrained(\"formal_model_bertLMHead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formal_model = BertForMaskedLM.from_pretrained(\"formal_model\")\n",
    "#formal_model = BertForMaskedLM.from_pretrained(\"formal_model_large\")\n",
    "#formal_model = BertForMaskedLM.from_pretrained(\"formal_model_large_nospace\")\n",
    "#formal_model = AutoModelForMaskedLM.from_pretrained(\"formal_model_large_nospace\")\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "formal_model =BertForMaskedLM.from_pretrained(\"formal_model_bertLMHead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_formal_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d427c63c5fd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_formal_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfull_formal_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfull_formal_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfull_formal_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#text=\"總統選舉登記結束，確定由藍綠白三方爭霸\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#text=\"質 感 劇 本 成 員 都 差 很 多 好 嗎 不 要 拿 腎 結 石 來 污 辱 這 群 人\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'full_formal_text' is not defined"
     ]
    }
   ],
   "source": [
    "text=full_formal_text[6]+full_formal_text[7]+full_formal_text[8]+full_formal_text[9]\n",
    "#text=\"總統選舉登記結束，確定由藍綠白三方爭霸\"\n",
    "#text=\"質 感 劇 本 成 員 都 差 很 多 好 嗎 不 要 拿 腎 結 石 來 污 辱 這 群 人\"\n",
    "\n",
    "text=text.replace(\" \",\"\")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-815b46f389df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "num_sentences = 1  \n",
    "#model=AutoModelForMaskedLM.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "\n",
    "\n",
    "for _ in range(num_sentences):\n",
    "  \n",
    "    prompt = text\n",
    "    \n",
    "  \n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    #input_ids = new_tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"]\n",
    " \n",
    "    outputs = formal_model.generate(input_ids, max_length=100, num_beams=3, no_repeat_ngram_size=1, do_sample=True, top_k=30,top_p=0.95)\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    " \n",
    "    print(\"Generated Sentence:\", generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "informal\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM,BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained('ckiplab/bert-tiny-chinese')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-chinese') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"informal.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    data=f.readlines()\n",
    "informal_text=[]\n",
    "for i in data:\n",
    "    informal_text.append(i[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59955"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=[]\n",
    "for i in informal_text:\n",
    "    x=i.replace(\" \",'')\n",
    "    f.append(x)\n",
    "    \n",
    "informal_text=f\n",
    "len(informal_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11990"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informal_longer=[]\n",
    "for i in range(0,len(informal_text)-5,5):\n",
    "    text=informal_text[i]+informal_text[i+1]+informal_text[i+2]+informal_text[i+3]+informal_text[i+4]\n",
    "    informal_longer.append(text)\n",
    "len(informal_longer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  6549,  2697,  1206,  3315,  2768,  1519,  6963,  2345,  2523,\n",
       "         1914,  1962,  1621,   679,  6206,  2897,  5575,  5178,  4767,   889,\n",
       "         3738,  6802,  6857,  5408,   782,  1728,  4158,   138,   163, 11316,\n",
       "         8303,  8148,   140,   679,  3221,  1378,  4124,   782,  8024,  3221,\n",
       "         3504,  1751,   782,  4265,  1894,  2218,  3221,   138,   163, 11316,\n",
       "         8303,  8148,   140,  4511,   712,  6235,  3297,  2527,  3647,   749,\n",
       "         1525,   943,  5143,   679,  5562,  5059,   872,  1558,  3297,   679,\n",
       "         5562,  5059,  4638,  5080,  1606,  1914,   749,  5503,  2125,  2798,\n",
       "         4692,  3472,  4413,  5143,  1888,   671,  1831,  5523,  2094,   102,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids=tokenizer(informal_longer,return_tensors=\"pt\", padding=True, truncation=True)[\"input_ids\"]\n",
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FXZ\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    dataset = TensorDataset(input_ids)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    for batch in dataloader:\n",
    "        outputs = model(input_ids=batch[0])\n",
    "        loss = criterion(outputs.logits.view(-1, model.config.vocab_size), batch[0].view(-1))\n",
    "        print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.0117, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2308, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3010, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5528, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8288, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1685, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6666, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4070, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2983, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2351, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1956, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1924, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1750, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1688, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1553, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1453, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0988, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0918, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0861, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0838, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0787, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0767, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0708, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0692, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0608, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0546, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0464, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0401, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0307, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0176, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0139, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0069, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0052, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.8577e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.9753e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.4789e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.7496e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.6168e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.8092e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.9392e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.3632e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.7518e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.1477e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.8229e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.7424e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.0843e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.2326e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.5066e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.8768e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.5202e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.3320e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.5785e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.5037e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.9626e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.9212e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.7391e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.5091e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.8134e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.6465e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.3244e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.4005e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.4752e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.6869e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.2237e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.3394e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.2417e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.6193e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.0953e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.6852e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.0733e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.9219e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.5900e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.0576e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.5934e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.4093e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.4141e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.4783e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.8376e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.0422e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.0288e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.6238e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.7251e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.0552e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.0298e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.3847e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.8029e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.4928e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.1705e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.4211e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.9851e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.6595e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.8113e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.5146e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.8495e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.8570e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.6726e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.9475e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.3002e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.9079e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.3835e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.6549e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.4764e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.0876e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.4443e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.8322e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.4683e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.0197e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.8286e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.6794e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.7520e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2977e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.9813e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.6815e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.2943e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.3603e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.6721e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.4529e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.3268e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.6288e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.5002e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.3924e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.8067e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.5527e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.6845e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.1189e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.2728e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.3310e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.5924e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.7685e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.4131e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.7894e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.6874e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.3788e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8970e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8028e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2747e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2460e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.6337e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.5761e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.3898e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.0461e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.9098e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.6631e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.5473e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.9726e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.3313e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.8876e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.9819e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.3380e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.5861e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.9541e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.8998e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.6875e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8301e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2294e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.1336e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.5285e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.1338e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7876e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4664e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.1305e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.9218e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.9515e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3453e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.1524e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8911e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2480e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.5842e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.9493e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.9991e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.0517e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.6453e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.9635e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.3069e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.5351e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2606e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.1734e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7604e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7616e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.9985e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.9186e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.1256e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.2181e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.0277e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5273e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.0069e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.9319e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0841e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4873e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.0588e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.6876e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.9769e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7272e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.2528e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.0537e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.0326e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.6261e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5664e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8787e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7049e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7940e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5327e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7441e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2765e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3496e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7385e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1430e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.1955e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.0310e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0020e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.1695e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.9847e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.4428e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0869e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8060e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4938e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.8516e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8252e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.9227e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.9868e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.9882e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7940e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2601e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1833e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8405e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.3561e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.6348e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.6680e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3474e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0610e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4146e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4951e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2376e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4972e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2090e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1949e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.1663e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0643e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4415e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.5848e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1856e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3269e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7870e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0710e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5123e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.0289e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8746e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.7815e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7911e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.4186e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0014e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6335e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7033e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6227e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0297e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7726e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.6227e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5280e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0138e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0639e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.5382e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9523e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9411e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.0601e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3104e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.5070e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3240e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.0014e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7783e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.1451e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4016e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5160e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.1376e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.0354e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6968e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4960e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.6562e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9527e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.6512e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6541e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.3741e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7066e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7238e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4573e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2593e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4270e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6152e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4014e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7756e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4834e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7099e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6959e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.0853e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3454e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0595e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0687e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1785e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7730e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0867e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5043e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.6256e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2776e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5721e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6304e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7197e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2042e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7878e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.0749e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2246e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3071e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7973e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0687e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4344e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7705e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6382e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8484e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.5368e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1544e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2708e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.9160e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.6185e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3421e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1838e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.0003e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.2598e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1290e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2259e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9072e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2231e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7368e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1523e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5592e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.0584e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2136e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8025e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3278e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2487e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2545e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.0205e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7039e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1465e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3323e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1849e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1341e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3827e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1516e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5534e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4983e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1010e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4190e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8542e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0625e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9757e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4923e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2024e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7479e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7172e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4204e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1080e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5342e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7932e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.0243e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.0054e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1660e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8396e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6085e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7216e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9948e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7528e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8080e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9394e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6412e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5523e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3657e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.0154e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.0100e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8922e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6764e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.0238e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9903e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6084e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7634e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2662e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8085e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3723e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1055e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4048e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4187e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3022e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1985e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9252e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7684e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8656e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9708e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8991e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8624e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8328e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6174e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.0506e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7418e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4399e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6909e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9715e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7022e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3080e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6244e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.8888e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1062e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3691e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.2313e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1764e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5097e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7511e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2639e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8816e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2033e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6246e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7624e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6068e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7902e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4659e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6790e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9852e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2370e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7915e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4677e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9834e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4705e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3483e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7495e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8635e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5101e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8001e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8476e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3517e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8385e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8930e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7382e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7723e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4209e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7087e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9658e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2309e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6274e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9731e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3644e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6600e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4879e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2095e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0933e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.0227e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2429e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1035e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4686e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4550e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5692e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4585e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8032e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6530e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3455e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6033e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1444e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2516e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2865e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8422e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0733e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.0964e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6428e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9243e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6434e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8957e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1593e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4282e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0997e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4338e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1260e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.0281e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9587e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6516e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3605e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8131e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9967e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6358e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2812e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1458e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1068e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4130e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8625e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4307e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2591e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0945e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8003e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3776e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4900e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1200e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2086e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4482e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9333e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5226e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6140e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2228e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7262e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8282e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2980e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5304e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4687e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9366e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1482e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1449e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0908e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0278e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5788e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0701e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8608e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0022e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3297e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8730e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4141e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9812e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3760e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2672e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8656e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6712e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1785e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3249e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2206e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0486e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7932e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8180e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1800e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0409e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4648e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2343e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8737e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3325e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9704e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5520e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8112e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0915e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0229e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0565e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2373e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8727e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9135e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3797e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5244e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7775e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3668e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7197e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9694e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1839e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0767e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0168e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9914e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9325e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2205e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2823e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1996e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0320e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7287e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2235e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8618e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8057e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9195e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9055e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5924e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1682e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8236e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7426e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7729e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9347e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5554e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7828e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2859e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8777e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3742e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6324e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2764e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6342e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7422e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3346e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9044e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7423e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5000e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.0726e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9319e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2057e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3425e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6881e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5683e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7230e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7390e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6074e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4511e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8700e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7620e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7467e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8739e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5029e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4772e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7824e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6977e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0136e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.3399e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0675e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5346e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8075e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6178e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4418e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8358e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7579e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4845e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1413e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0547e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5899e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7779e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7243e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5686e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4639e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4060e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7434e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2708e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5678e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4965e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1490e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9383e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8031e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5050e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0219e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1551e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9538e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0026e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5894e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7970e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6569e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5369e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1668e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5832e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0642e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7104e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3628e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6128e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1170e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4221e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5944e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2418e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9762e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7247e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4563e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5171e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6037e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1080e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6972e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6348e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8905e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1793e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7623e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7974e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4209e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0886e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7390e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4311e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6261e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6251e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5772e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1788e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3266e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4333e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3632e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5619e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1864e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4249e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1992e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4030e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5570e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1994e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6108e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1140e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8174e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3707e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5927e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1161e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2289e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9332e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3791e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2845e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5716e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6499e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5463e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5495e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5671e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5804e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3536e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9904e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1259e-05, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0118e-05, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    dataset = TensorDataset(input_ids)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    for batch in dataloader:\n",
    "        outputs = model(input_ids=batch[0])\n",
    "        loss = criterion(outputs.logits.view(-1, model.config.vocab_size), batch[0].view(-1))\n",
    "        print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"informal_model_bertLMHead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "informal_model =BertForMaskedLM.from_pretrained(\"formal_model_bertLMHead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cyclegan\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "鑑別器\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-58-43d0b04c7fbb>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  formal_tensor = torch.tensor(formal_tensor)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 1.1148816347122192\n",
      "Epoch [2/15], Loss: 0.7904165387153625\n",
      "Epoch [3/15], Loss: 0.7788472771644592\n",
      "Epoch [4/15], Loss: 0.7649118900299072\n",
      "Epoch [5/15], Loss: 0.7498632073402405\n",
      "Epoch [6/15], Loss: 0.7341395020484924\n",
      "Epoch [7/15], Loss: 0.7179298996925354\n",
      "Epoch [8/15], Loss: 0.7731238007545471\n",
      "Epoch [9/15], Loss: 0.7235013246536255\n",
      "Epoch [10/15], Loss: 0.6862377524375916\n",
      "Epoch [11/15], Loss: 0.6775649189949036\n",
      "Epoch [12/15], Loss: 0.6679651737213135\n",
      "Epoch [13/15], Loss: 0.6575396656990051\n",
      "Epoch [14/15], Loss: 0.6463772058486938\n",
      "Epoch [15/15], Loss: 0.6345552802085876\n",
      "真假概率: 0.515231728553772\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "formal_tensor = torch.tensor(formal_tensor)\n",
    "formal_tensor = formal_tensor.to(torch.float)\n",
    "input_size = 25\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid() \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "real_text_data = formal_tensor[:1000] \n",
    "fake_text_data = torch.randn(1000, input_size)  \n",
    "\n",
    "\n",
    "discriminator = Discriminator()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(discriminator.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 15\n",
    "losses = [] \n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    outputs_real = discriminator(real_text_data)\n",
    "    labels_real = torch.ones(outputs_real.size())  \n",
    "    loss_real = criterion(outputs_real, labels_real)\n",
    "\n",
    "    outputs_fake = discriminator(fake_text_data)\n",
    "    labels_fake = torch.zeros(outputs_fake.size()) \n",
    "    loss_fake = criterion(outputs_fake, labels_fake)\n",
    "\n",
    "    total_loss = loss_real + loss_fake\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    losses.append(total_loss.item())\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss.item()}\")\n",
    "\n",
    "\n",
    "input_text = torch.randn(1, input_size)  \n",
    "with torch.no_grad():\n",
    "    output_prob = discriminator(input_text)\n",
    "\n",
    "print(\"真假概率:\", output_prob.item()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([59962, 25])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formal_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27958f768dcca3a929804bc6fbe38aedd46970db20e3e9a2a0a7634f9c4148a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
